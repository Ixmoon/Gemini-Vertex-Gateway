# file: getkeys.py

import sys
import os
import random
import tempfile
import shutil
import time
import getpass
import concurrent.futures
import queue
import threading
import logging
import time
from functools import wraps
from google.api_core import exceptions as google_exceptions
from grpc import RpcError

# --- å†…éƒ¨å¹¶å‘æ§åˆ¶ ---
# ä¸ºé¿å…çº¿ç¨‹æ•°çˆ†ç‚¸å¼å¢é•¿ï¼Œå†…éƒ¨ä»»åŠ¡ä½¿ç”¨å›ºå®šçš„å¹¶å‘æ•°ï¼Œè€Œä¸é‡ç”¨UIå±‚çº§çš„max_workers
PROJECT_CHECK_CONCURRENCY = 12  # å¹¶è¡Œæ£€æŸ¥å·²æœ‰é¡¹ç›®çš„æœ€å¤§çº¿ç¨‹æ•°
PROJECT_CONFIG_CONCURRENCY = 4 # å¹¶è¡Œé…ç½®æ–°é¡¹ç›®çš„æœ€å¤§çº¿ç¨‹æ•°


# çº¿ç¨‹å±€éƒ¨å­˜å‚¨ï¼Œç”¨äºæ—¥å¿—è®°å½•ä¸Šä¸‹æ–‡
thread_local = threading.local()

class ContextFilter(logging.Filter):
    """ä¸€ä¸ªå°†çº¿ç¨‹å±€éƒ¨ä¸Šä¸‹æ–‡æ³¨å…¥æ—¥å¿—è®°å½•çš„è¿‡æ»¤å™¨ã€‚"""
    def filter(self, record):
        record.account = getattr(thread_local, 'account', 'N/A')
        record.project = getattr(thread_local, 'project', '-----')
        return True

def setup_global_logging(log_queue=None, level=logging.INFO):
    """é…ç½®å…¨å±€ï¼ˆæ ¹ï¼‰æ—¥å¿—è®°å½•å™¨ã€‚"""
    root_logger = logging.getLogger()
    # é…ç½®ä¸€æ¬¡å³å¯
    if root_logger.hasHandlers():
        root_logger.handlers.clear()
    
    root_logger.setLevel(level)
    root_logger.addFilter(ContextFilter())

    formatter = logging.Formatter(
        '[%(asctime)s] [%(levelname)-5s] [%(account)s] [%(project)s] %(message)s',
        datefmt='%H:%M:%S'
    )

    if log_queue:
        from logging.handlers import QueueHandler
        handler = QueueHandler(log_queue)
    else:
        handler = logging.StreamHandler(sys.stdout)
    
    handler.setFormatter(formatter)
    root_logger.addHandler(handler)

def create_thread_logger(name, log_stream):
    """ä¸ºå•ä¸ªçº¿ç¨‹åˆ›å»ºä¸€ä¸ªéš”ç¦»çš„ã€ä¸ä¼ æ’­çš„æ—¥å¿—è®°å½•å™¨ã€‚"""
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    logger.propagate = False  # è¿™æ˜¯å…³é”®ï¼šé˜²æ­¢æ—¥å¿—è¢«å‘é€åˆ°æ ¹è®°å½•å™¨
    
    # æ¸…é™¤æ—§çš„å¤„ç†å™¨ä»¥é˜²ä¸‡ä¸€
    if logger.hasHandlers():
        logger.handlers.clear()

    # å…³é”®ä¿®å¤ï¼šä¸ºçº¿ç¨‹çº§loggerä¹Ÿæ·»åŠ ä¸Šä¸‹æ–‡è¿‡æ»¤å™¨
    logger.addFilter(ContextFilter())
        
    formatter = logging.Formatter(
        '[%(asctime)s] [%(levelname)-5s] [%(account)s] [%(project)s] %(message)s',
        datefmt='%H:%M:%S'
    )
    stream_handler = logging.StreamHandler(log_stream)
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)
    
    return logger

def retry_on_unavailable(max_retries=3, delay=2, backoff=2):
    """
    A decorator to retry a function on google.api_core.exceptions.ServiceUnavailable and grpc.RpcError.
    It intelligently finds a logger instance from the function's arguments.
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            logger_instance = None
            for arg in args:
                if isinstance(arg, logging.Logger):
                    logger_instance = arg
                    break
            if 'logger' in kwargs:
                logger_instance = kwargs['logger']
            
            if not logger_instance:
                logger_instance = logging.getLogger() # Fallback to root logger

            current_delay = delay
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except (google_exceptions.ServiceUnavailable, RpcError):
                    logger_instance.warning(
                        f"'{func.__name__}' failed with ServiceUnavailable or gRPC error (Attempt {attempt + 1}/{max_retries}). "
                        f"Retrying in {current_delay}s..."
                    )
                    if attempt + 1 == max_retries:
                        logger_instance.error(f"All retry attempts for '{func.__name__}' failed.")
                        raise
                    time.sleep(current_delay)
                    current_delay *= backoff
        return wrapper
    return decorator


# å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™ç»™å‡ºæ¸…æ™°çš„é”™è¯¯æç¤º
try:
    from google.cloud import resourcemanager, service_usage, api_keys
    from google.oauth2 import credentials as google_credentials
    from google.auth import exceptions as google_auth_exceptions
    from auto_login import perform_login_automation
    import undetected_chromedriver as uc
    from constants import (STATUS_PROCESSING, STATUS_SUCCESS, STATUS_FAILURE,
                           STATUS_LOGIN_FAILED, STATUS_PARTIAL_SUCCESS, STATUS_PENDING,
                           DependenciesMissingError, GCloudNotInstalledError)
except ImportError as e:
    # ç«‹å³æŠ›å‡ºè‡ªå®šä¹‰å¼‚å¸¸ï¼Œè€Œä¸æ˜¯é€€å‡º
    raise DependenciesMissingError(
        "é”™è¯¯: ç¼ºå°‘å¿…è¦çš„åº“ã€‚\n"
        "è¯·è¿è¡Œ: pip install google-auth google-cloud-resource-manager "
        "google-cloud-service-usage google-cloud-api-keys selenium "
        "undetected-chromedriver"
    ) from e

def check_gcloud_installed():
    """æ£€æŸ¥gcloud CLIæ˜¯å¦å·²å®‰è£…å¹¶è¿”å›å…¶è·¯å¾„"""
    gcloud_path = shutil.which('gcloud')
    if not gcloud_path:
        raise GCloudNotInstalledError(
            "é”™è¯¯: æœªæ‰¾åˆ° 'gcloud' å‘½ä»¤è¡Œå·¥å…·ã€‚\n"
            "è¯·æŒ‰ç…§å®˜æ–¹æ–‡æ¡£å®‰è£… Google Cloud SDK: \n"
            "https://cloud.google.com/sdk/docs/install"
        )
    return gcloud_path

@retry_on_unavailable()
def enable_api_if_not_enabled(su_client, project_id, logger):
    """æ£€æŸ¥å¹¶å¯ç”¨Generative Language APIã€‚"""
    service_name = f"projects/{project_id}/services/generativelanguage.googleapis.com"
    try:
        service = su_client.get_service(request={'name': service_name})
        if service.state == service_usage.State.ENABLED:
            logger.info("âœ… API å·²å¯ç”¨ã€‚")
            return True
    except (google_exceptions.ServiceUnavailable, RpcError):
        raise # Re-raise for the decorator to handle retries
    except google_exceptions.NotFound:
        logger.info("â„¹ï¸ API æœªå¯ç”¨ï¼Œæ­£åœ¨å°è¯•å¯ç”¨...")
    except Exception:
        logger.error("âŒ æ£€æŸ¥APIçŠ¶æ€æ—¶å‡ºé”™:", exc_info=True)
        return False

    try:
        su_client.enable_service(request={'name': service_name}).result(timeout=300)
        logger.info("âœ… API å¯ç”¨æˆåŠŸã€‚")
        return True
    except (google_exceptions.ServiceUnavailable, RpcError):
        raise # Re-raise for the decorator to handle retries
    except Exception:
        logger.error("âŒ å¯ç”¨APIæ—¶å‡ºé”™:", exc_info=True)
        return False

@retry_on_unavailable()
def create_api_key_if_not_exists(ak_client, project_id, logger):
    """æ£€æŸ¥é¡¹ç›®æ˜¯å¦å·²æœ‰APIå¯†é’¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºå¹¶è¿”å›å¯†é’¥å­—ç¬¦ä¸²ã€‚"""
    try:
        keys = ak_client.list_keys(parent=f"projects/{project_id}/locations/global")
        for key in keys:
            if key.restrictions is None or not key.restrictions.api_targets:
                logger.info("âœ… å‘ç°å·²å­˜åœ¨çš„APIå¯†é’¥ã€‚")
                key_string = ak_client.get_key_string(request={'name': key.name}).key_string
                return key_string

        logger.info("â„¹ï¸ æœªå‘ç°å¯ç”¨APIå¯†é’¥ï¼Œæ­£åœ¨åˆ›å»º...")
        key_request = api_keys.CreateKeyRequest(
            parent=f"projects/{project_id}/locations/global",
            key=api_keys.Key(display_name="Auto-Generated Gemini Key")
        )
        api_key_obj = ak_client.create_key(request=key_request).result(timeout=300)
        logger.info("âœ… APIå¯†é’¥åˆ›å»ºæˆåŠŸã€‚")
        return api_key_obj.key_string
    
    except (google_exceptions.ServiceUnavailable, RpcError):
        raise # Re-raise for the decorator to handle retries
    except Exception:
        logger.error("âŒ å¤„ç†APIå¯†é’¥æ—¶å‡ºé”™:", exc_info=True)
        return None

def process_existing_project(project_id, credentials, account_email, logger):
    """å¤„ç†å•ä¸ªç°æœ‰é¡¹ç›®ï¼šæ£€æŸ¥APIå’Œå¯†é’¥ï¼ŒæˆåŠŸåˆ™è¿”å›å¯†é’¥ã€‚"""
    try:
        thread_local.account = account_email
        thread_local.project = project_id
        logger.info("--- å¼€å§‹å¤„ç†ç°æœ‰é¡¹ç›® ---")
        su_client = service_usage.ServiceUsageClient(credentials=credentials)
        ak_client = api_keys.ApiKeysClient(credentials=credentials)

        if enable_api_if_not_enabled(su_client, project_id, logger):
            key = create_api_key_if_not_exists(ak_client, project_id, logger)
            if key:
                logger.info("âœ… æˆåŠŸè·å–å¯†é’¥ã€‚")
                return key
    except Exception as e:
        logger.error(f"âŒ å¤„ç†é¡¹ç›®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
    finally:
        thread_local.project = '-----'
    return None

def configure_project_and_get_key(project_id, credentials, account_email, logger):
    """(é…ç½®è€…)æ¥æ”¶ä¸€ä¸ªé¡¹ç›®IDï¼Œä¸ºå…¶å¯ç”¨APIå¹¶åˆ›å»ºå¯†é’¥ã€‚"""
    try:
        thread_local.account = account_email
        thread_local.project = project_id
        logger.info("âš™ï¸ å¼€å§‹é…ç½®é¡¹ç›®...")
        su_client = service_usage.ServiceUsageClient(credentials=credentials)
        ak_client = api_keys.ApiKeysClient(credentials=credentials)

        if enable_api_if_not_enabled(su_client, project_id, logger):
            key = create_api_key_if_not_exists(ak_client, project_id, logger)
            if key:
                logger.info("âœ… æˆåŠŸè·å–å¯†é’¥ã€‚")
                return key
    except Exception:
        logger.error("âŒ é…ç½®é¡¹ç›®æ—¶å‡ºé”™:", exc_info=True)
    finally:
        thread_local.project = '-----'
    return None


def creator_task(credentials, projects_to_configure_queue, account_email, logger, existing_project_display_names, projects_to_create=0, account_stop_event=None, global_stop_event=None):
    """(åˆ›å»ºè€…)å¾ªç¯åˆ›å»ºé¡¹ç›®ï¼Œç›´åˆ°è¾¾åˆ°é…é¢æˆ–ç›®æ ‡æ•°é‡ã€‚"""
    thread_local.account = account_email
    project_counter = 1
    created_count = 0
    while not ((global_stop_event and global_stop_event.is_set()) or (account_stop_event and account_stop_event.is_set())):
        if projects_to_create > 0 and created_count >= projects_to_create:
            logger.info(f"å·²è¾¾åˆ°è®¡åˆ’åˆ›å»ºçš„é¡¹ç›®æ•° ({projects_to_create})ï¼Œåˆ›å»ºè€…ä»»åŠ¡åœæ­¢ã€‚")
            break
        display_name = f"my-project-{project_counter}"
        
        # æ£€æŸ¥æ˜¾ç¤ºåç§°æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è·³è¿‡å¹¶é€’å¢è®¡æ•°å™¨
        if display_name in existing_project_display_names:
            logger.info(f"â„¹ï¸ é¡¹ç›®æ˜¾ç¤ºåç§° '{display_name}' å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
            project_counter += 1
            continue

        # å¿…é¡»åœ¨å®¢æˆ·ç«¯ç”Ÿæˆå”¯ä¸€çš„ project_idã€‚
        project_id = f"{display_name}-{random.randint(1000, 9999)}"
        
        thread_local.project = project_id
        logger.info(f"â–¶ï¸ æäº¤åˆ›å»ºæ–°é¡¹ç›® '{display_name}' (ID: {project_id}) çš„è¯·æ±‚...")
        
        try:
            rm_client = resourcemanager.ProjectsClient(credentials=credentials)
            project_obj = resourcemanager.Project(
                project_id=project_id,
                display_name=display_name
            )
            
            operation = rm_client.create_project(project=project_obj)
            operation.result(timeout=300)
            
            logger.info(f"âœ… é¡¹ç›® '{display_name}' (ID: {project_id}) åˆ›å»ºæˆåŠŸï¼Œå·²åŠ å…¥é…ç½®é˜Ÿåˆ—ã€‚")
            projects_to_configure_queue.put(project_id)
            created_count += 1
            # æˆåŠŸåˆ›å»ºåï¼Œä¹Ÿå°†æ–°åç§°åŠ å…¥é›†åˆï¼Œä»¥é˜²ä¸‡ä¸€
            existing_project_display_names.add(display_name)
            project_counter += 1

        except google_exceptions.AlreadyExists:
            logger.warning(f"âš ï¸ é¡¹ç›®ID '{project_id}' å·²å­˜åœ¨ï¼ˆå°æ¦‚ç‡äº‹ä»¶ï¼‰ï¼Œå°†ç”Ÿæˆæ–°IDé‡è¯•...")
            continue # ç›´æ¥è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯ï¼Œproject_counterä¸å˜ï¼Œä½†ä¼šç”Ÿæˆæ–°çš„éšæœºID
        except google_exceptions.ResourceExhausted:
            logger.warning("â¹ï¸ å·²è¾¾åˆ°é¡¹ç›®åˆ›å»ºé…é¢ï¼Œåˆ›å»ºè€…ä»»åŠ¡åœæ­¢ã€‚")
            break
        except google_exceptions.PermissionDenied as e:
            if "project_creation_quota" in str(e) or "PROJECT_CREATION_QUOTA" in str(e):
                logger.warning("â¹ï¸ å·²è¾¾åˆ°é¡¹ç›®åˆ›å»ºé…é¢ï¼Œåˆ›å»ºè€…ä»»åŠ¡åœæ­¢ã€‚")
            else:
                logger.error("âŒ åˆ›å»ºé¡¹ç›®æ—¶æƒé™è¢«æ‹’ç» (éé…é¢é—®é¢˜):", exc_info=True)
            break
        except Exception:
            logger.error("âŒ åˆ›å»ºé¡¹ç›®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯:", exc_info=True)
            break
        finally:
            thread_local.project = '-----'

def handle_existing_projects(credentials, logger, all_keys, lock, account_email, projects, desired_keys=0, account_stop_event=None, global_stop_event=None):
    """(ä¸»ä»»åŠ¡1) å¹¶è¡Œå¤„ç†æ‰€æœ‰ç°æœ‰é¡¹ç›®ã€‚"""
    thread_local.account = account_email
    logger.info("--- (ä»»åŠ¡1) å¼€å§‹å¹¶è¡Œå¤„ç†ç°æœ‰é¡¹ç›® ---")
    if not projects:
        logger.info("æ²¡æœ‰å‘ç°ç°æœ‰é¡¹ç›®ã€‚")
        return
    
    logger.info(f"å¼€å§‹å¤„ç† {len(projects)} ä¸ªç°æœ‰é¡¹ç›®ã€‚")
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=PROJECT_CHECK_CONCURRENCY) as executor:
            future_to_project = {executor.submit(process_existing_project, p.project_id, credentials, account_email, logger): p for p in projects}
            for future in concurrent.futures.as_completed(future_to_project):
                if (global_stop_event and global_stop_event.is_set()) or (account_stop_event and account_stop_event.is_set()):
                    logger.info("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæå‰ç»ˆæ­¢æ£€æŸ¥ç°æœ‰é¡¹ç›®ã€‚")
                    executor.shutdown(wait=False, cancel_futures=True)
                    break
                key = future.result()
                if key:
                    with lock:
                        all_keys.add(key)
                        # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ç›®æ ‡æ•°é‡
                        if desired_keys > 0 and len(all_keys) >= desired_keys:
                            logger.info(f"å·²ä¸ºè¯¥è´¦å·è·å– {len(all_keys)}/{desired_keys} ä¸ªå¯†é’¥ï¼Œè¾¾åˆ°ç›®æ ‡ã€‚")
                            if account_stop_event:
                                account_stop_event.set() # å‘å‡ºé’ˆå¯¹æ­¤è´¦å·çš„åœæ­¢ä¿¡å·
                            executor.shutdown(wait=False, cancel_futures=True)
                            break
    except google_exceptions.PermissionDenied:
        logger.error("âŒ æƒé™ä¸è¶³ï¼Œæ— æ³•åˆ—å‡ºé¡¹ç›®ã€‚è¯·æ£€æŸ¥è´¦å·æ˜¯å¦æ‹¥æœ‰ 'Project Viewer' æˆ–æ›´é«˜æƒé™ã€‚", exc_info=True)
    except google_auth_exceptions.RefreshError:
        logger.error("âŒ èº«ä»½éªŒè¯å‡­æ®å·²è¿‡æœŸæˆ–å¤±æ•ˆï¼Œæ— æ³•åˆ·æ–°ã€‚è¯·å°è¯•é‡æ–°ç™»å½•ã€‚", exc_info=True)
    except Exception:
        logger.error("âŒ åˆ—å‡ºæˆ–å¤„ç†ç°æœ‰é¡¹ç›®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯:", exc_info=True)
    logger.info("--- (ä»»åŠ¡1) å¤„ç†ç°æœ‰é¡¹ç›®å®Œæˆ ---")

def handle_new_projects(credentials, logger, all_keys, lock, account_email, projects, projects_to_create=0, account_stop_event=None, global_stop_event=None, desired_keys=0):
    """(ä¸»ä»»åŠ¡2) ä½¿ç”¨åˆ›å»ºè€…/é…ç½®è€…æ¨¡å¼å¤„ç†æ–°é¡¹ç›®ã€‚"""
    thread_local.account = account_email
    logger.info("--- (ä»»åŠ¡2) å¯åŠ¨åˆ›å»ºè€…/é…ç½®è€…æ¨¡å¼ä»¥ç”Ÿæˆæ–°å¯†é’¥ ---")
    
    projects_to_configure_queue = queue.Queue()
    existing_project_display_names = {p.display_name for p in projects}
    
    def configurator_worker(email_for_thread, logger_for_thread):
        """é…ç½®è€…çº¿ç¨‹çš„å·¥ä½œå†…å®¹"""
        thread_local.account = email_for_thread
        while not ((global_stop_event and global_stop_event.is_set()) or (account_stop_event and account_stop_event.is_set())):
            try:
                project_id = projects_to_configure_queue.get(timeout=1)
                if project_id is None: # Shutdown signal
                    break # Exit thread
                key = configure_project_and_get_key(project_id, credentials, email_for_thread, logger_for_thread)
                if key:
                    with lock:
                        all_keys.add(key)
                        if desired_keys > 0 and len(all_keys) >= desired_keys:
                            logger.info(f"å·²ä¸ºè¯¥è´¦å·è·å– {len(all_keys)}/{desired_keys} ä¸ªå¯†é’¥ï¼Œè¾¾åˆ°ç›®æ ‡ã€‚")
                            if account_stop_event:
                                account_stop_event.set()
                projects_to_configure_queue.task_done()
            except queue.Empty:
                continue # ç»§ç»­å¾ªç¯æ£€æŸ¥åœæ­¢ä¿¡å·

    creator_thread = threading.Thread(
        target=creator_task,
        args=(credentials, projects_to_configure_queue, account_email, logger, existing_project_display_names, projects_to_create, account_stop_event, global_stop_event)
    )
    creator_thread.start()

    configurator_threads = []
    for _ in range(PROJECT_CONFIG_CONCURRENCY):
        t = threading.Thread(target=configurator_worker, args=(account_email, logger))
        t.daemon = True
        t.start()
        configurator_threads.append(t)

    creator_thread.join() # ç­‰å¾…åˆ›å»ºè€…çº¿ç¨‹ç»“æŸï¼ˆå³è¾¾åˆ°é…é¢ï¼‰
    projects_to_configure_queue.join() # ç­‰å¾…æ‰€æœ‰å·²å…¥é˜Ÿçš„é…ç½®ä»»åŠ¡å®Œæˆ

    # æ‰€æœ‰çœŸå®ä»»åŠ¡å·²å®Œæˆï¼Œç°åœ¨é€šè¿‡å‘é€Noneä¿¡å·æ¥åœæ­¢å·¥ä½œçº¿ç¨‹
    for _ in range(len(configurator_threads)):
        projects_to_configure_queue.put(None)
    
    for t in configurator_threads:
        t.join(timeout=5) # ç­‰å¾…çº¿ç¨‹å¹²å‡€åœ°é€€å‡º

    logger.info("--- (ä»»åŠ¡2) å¤„ç†æ–°é¡¹ç›®å®Œæˆ ---")


import io

def process_account(account_email, password, gcloud_path, temp_dir, patched_driver_path, stop_event, browser_path=None, gui_queue=None, worker_id=0, desired_keys=0):
    """ä¸ºæŒ‡å®šè´¦å·æ‰§è¡Œå®Œæ•´çš„è®¤è¯å’Œèµ„æºåˆ›å»ºæµç¨‹ã€‚"""
    log_stream = io.StringIO()
    logger = create_thread_logger(f"account.{account_email}", log_stream)
    
    # å¦‚æœæœ‰GUIé˜Ÿåˆ—ï¼Œä¹Ÿä¸ºä¸»çº¿ç¨‹çš„loggeræ·»åŠ ä¸€ä¸ªé˜Ÿåˆ—å¤„ç†å™¨
    if gui_queue:
        from logging.handlers import QueueHandler
        queue_handler = QueueHandler(gui_queue)
        # ä½¿ç”¨æ ¹è®°å½•å™¨çš„æ ¼å¼åŒ–å™¨
        queue_handler.setFormatter(logging.getLogger().handlers[0].formatter)
        logger.addHandler(queue_handler)

    thread_local.account = account_email
    result = {"account": account_email, "keys": set(), "status": STATUS_FAILURE, "reason": ""}

    try:
        # ç«‹å³é€šçŸ¥GUIå¼€å§‹å¤„ç†æ­¤è´¦å·
        if gui_queue:
            gui_queue.put({"account": account_email, "status": STATUS_PROCESSING})

        # --- æ­¥éª¤ 1: ç™»å½• ---
        login_success = perform_login_automation(account_email, password, gcloud_path, temp_dir, patched_driver_path, stop_event, logger, browser_path, worker_id)
        if stop_event.is_set():
            logger.warning("å¤–éƒ¨ä¿¡å·ä¸­æ–­ï¼Œç™»å½•æµç¨‹æœªå®Œæˆã€‚")
            result["status"] = STATUS_PENDING
            result["reason"] = "è¢«ç”¨æˆ·å¼ºåˆ¶ä¸­æ–­"
            return result
        if not login_success:
            logger.error("ç™»å½•å¤±è´¥ï¼Œç»ˆæ­¢æ“ä½œã€‚")
            result["status"] = STATUS_LOGIN_FAILED
            
            # ä»æ—¥å¿—ä¸­æå–å…·ä½“çš„å¤±è´¥åŸå› 
            log_content = log_stream.getvalue()
            first_error = ""
            # ä»åå¾€å‰æ‰¾ï¼Œæœ€åä¸€æ¡é”™è¯¯é€šå¸¸æœ€èƒ½è¯´æ˜é—®é¢˜
            for line in reversed(log_content.splitlines()):
                if "âŒ" in line:
                    parts = line.split('] ')
                    # æå–çœŸæ­£çš„æ¶ˆæ¯éƒ¨åˆ†
                    first_error = '] '.join(parts[4:]) if len(parts) > 4 else line
                    break
            result["reason"] = first_error if first_error else "ç™»å½•å¤±è´¥æˆ–è¢«æ‰‹åŠ¨ä¸­æ–­ã€‚"
            return result

        # --- æ­¥éª¤ 2: åŠ è½½å‡­æ® ---
        logger.info("æ­£åœ¨åŠ è½½å‡­è¯...")
        adc_path = os.path.join(temp_dir, "application_default_credentials.json")
        credentials = google_credentials.Credentials.from_authorized_user_file(adc_path)
        logger.info("âœ… å‡­è¯åŠ è½½æˆåŠŸã€‚")
        lock = threading.Lock()
        
        # --- æ­¥éª¤ 3: ä¸€æ¬¡æ€§è·å–æ‰€æœ‰é¡¹ç›® ---
        if stop_event.is_set():
            logger.warning("å¤–éƒ¨ä¿¡å·ä¸­æ–­ï¼Œè·³è¿‡é¡¹ç›®å¤„ç†ã€‚")
            result["status"] = STATUS_PENDING
            result["reason"] = "è¢«ç”¨æˆ·å¼ºåˆ¶ä¸­æ–­"
            return result

        logger.info("æ­£åœ¨ä¸€æ¬¡æ€§è·å–æ‰€æœ‰ç°æœ‰é¡¹ç›®åˆ—è¡¨...")
        try:
            rm_client = resourcemanager.ProjectsClient(credentials=credentials)
            all_projects = list(rm_client.search_projects())
            logger.info(f"âœ… å‘ç° {len(all_projects)} ä¸ªç°æœ‰é¡¹ç›®ã€‚")
        except Exception as e:
            logger.error(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œæ— æ³•ç»§ç»­: {e}", exc_info=True)
            result['status'] = STATUS_FAILURE
            result['reason'] = f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}"
            return result

        # --- æ­¥éª¤ 4: æ ¹æ®éœ€æ±‚å†³å®šä»»åŠ¡ç­–ç•¥ ---
        account_stop_event = threading.Event() # ä¸ºæ­¤è´¦å·åˆ›å»ºç‹¬ç«‹çš„åœæ­¢ä¿¡å·
        num_existing_projects = len(all_projects)
        logger.info(f"éœ€æ±‚å¯†é’¥æ•°: {'ä¸é™' if desired_keys == 0 else desired_keys}, ç°æœ‰é¡¹ç›®æ•°: {num_existing_projects}")

        # å¦‚æœç°æœ‰é¡¹ç›®å·²æ»¡è¶³éœ€æ±‚ï¼Œåˆ™åªæ£€æŸ¥ç°æœ‰é¡¹ç›®
        if desired_keys > 0 and num_existing_projects >= desired_keys:
            logger.info("ç°æœ‰é¡¹ç›®æ•°å·²æ»¡è¶³éœ€æ±‚ï¼Œä»…æ£€æŸ¥ç°æœ‰é¡¹ç›®ä»¥è·å–å¯†é’¥ã€‚")
            handle_existing_projects(credentials, logger, result["keys"], lock, account_email, all_projects, desired_keys, account_stop_event, stop_event)
        else:
            # è®¡ç®—éœ€è¦åˆ›å»ºçš„æ•°é‡
            projects_to_create = 0
            if desired_keys > 0:
                projects_to_create = desired_keys - num_existing_projects
                if projects_to_create < 0: projects_to_create = 0
                logger.info(f"é¡¹ç›®æ•°ä¸è¶³ï¼Œå°†å¹¶è¡Œæ£€æŸ¥ç°æœ‰é¡¹ç›®å¹¶å°è¯•åˆ›å»º {projects_to_create} ä¸ªæ–°é¡¹ç›®ã€‚")
            else:
                logger.info("æœªè®¾ç½®å¯†é’¥æ•°é™åˆ¶ï¼Œå°†å¹¶è¡Œæ£€æŸ¥ç°æœ‰é¡¹ç›®å¹¶åˆ›å»ºæ–°é¡¹ç›®ç›´åˆ°é…é¢ç”¨å°½ã€‚")

            # --- å¹¶è¡Œå¯åŠ¨ä¸¤ä¸ªä¸»ä»»åŠ¡ ---
            existing_projects_thread = threading.Thread(
                target=handle_existing_projects,
                args=(credentials, logger, result["keys"], lock, account_email, all_projects, desired_keys, account_stop_event, stop_event)
            )
            new_projects_thread = threading.Thread(
                target=handle_new_projects,
                args=(credentials, logger, result["keys"], lock, account_email, all_projects, projects_to_create, account_stop_event, stop_event, desired_keys)
            )

            existing_projects_thread.start()
            if projects_to_create > 0 or desired_keys == 0:
                new_projects_thread.start()

            # åœ¨ç­‰å¾…æ—¶ï¼Œå‘¨æœŸæ€§æ£€æŸ¥åœæ­¢ä¿¡å·
            # The loop should check both the global stop event and the account-specific one.
            threads_to_watch = [existing_projects_thread]
            if new_projects_thread.is_alive():
                threads_to_watch.append(new_projects_thread)

            while any(t.is_alive() for t in threads_to_watch):
                 if stop_event.is_set() or account_stop_event.is_set():
                     logger.warning("æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå°†ç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆ...")
                     if not account_stop_event.is_set():
                         account_stop_event.set() # Propagate stop signal to all sub-tasks
                     break
                 time.sleep(0.5)

            existing_projects_thread.join()
            if new_projects_thread.is_alive():
                new_projects_thread.join()

        # --- æ­¥éª¤ 5: è¿”å›ç»“æœ ---
        key_count = len(result["keys"])
        log_content = log_stream.getvalue()
        # æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦æœ‰é”™è¯¯æ ‡è®°
        has_errors = "âŒ" in log_content or "[ERROR]" in log_content or "[CRITICAL]" in log_content

        logger.info(f"--- ä»»åŠ¡å®Œæˆ, å…±è·å¾— {key_count} ä¸ªå¯†é’¥ ---")
        
        first_error = ""
        if has_errors:
            for line in reversed(log_content.splitlines()):
                if "âŒ" in line or "[ERROR]" in line or "[CRITICAL]" in line:
                    parts = line.split('] ')
                    first_error = '] '.join(parts[4:]) if len(parts) > 4 else line
                    break

        if key_count > 0:
            if has_errors:
                result["status"] = STATUS_PARTIAL_SUCCESS
                result["reason"] = first_error or "è·å–åˆ°å¯†é’¥ï¼Œä½†è¿‡ç¨‹ä¸­å­˜åœ¨æœªçŸ¥é”™è¯¯ã€‚"
            else:
                result["status"] = STATUS_SUCCESS
                result["reason"] = "" # æˆåŠŸæ—¶æ²¡æœ‰ç†ç”±
        else:  # key_count == 0
            result["status"] = STATUS_FAILURE
            result["reason"] = first_error or "æµç¨‹ç»“æŸï¼Œä½†æœªèƒ½è·å–åˆ°ä»»ä½•å¯†é’¥ã€‚"

    except Exception as e:
        logger.critical(f"å¤„ç†è´¦å· {account_email} æ—¶å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)
        result['status'] = STATUS_FAILURE # ç¡®ä¿çŠ¶æ€ä¸ºå¤±è´¥
        result['reason'] = f"å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"
    finally:
        # å¦‚æœæ˜¯å› ä¸ºä¸­æ–­è€Œé€€å‡ºï¼Œä¸”æ²¡æœ‰è·å¾—ä»»ä½•å¯†é’¥ï¼Œåˆ™æ ‡è®°ä¸ºæœªå¤„ç†
        if stop_event.is_set() and not result["keys"]:
            result['status'] = STATUS_PENDING
            result['reason'] = "è¢«ç”¨æˆ·å¼ºåˆ¶ä¸­æ–­"
        # å¦‚æœä¸­æ–­ä½†è·å¾—äº†éƒ¨åˆ†å¯†é’¥
        elif stop_event.is_set() and result["keys"]:
             result['status'] = STATUS_PARTIAL_SUCCESS
             result['reason'] = "è¢«ç”¨æˆ·å¼ºåˆ¶ä¸­æ–­"

        # åœ¨è¿”å›å‰ï¼Œå°†å¯†é’¥é›†åˆè½¬æ¢ä¸ºåˆ—è¡¨
        result['keys'] = list(result['keys'])
        # åœ¨å‡½æ•°æœ«å°¾ï¼Œè·å–æ‰€æœ‰æ•è·çš„æ—¥å¿—
        result['log'] = log_stream.getvalue()
        # æ­¤å¤„ä¸èƒ½å…³é—­log_streamï¼Œå› ä¸ºloggingæ¨¡å—å¯èƒ½ä»åœ¨å…¶ä»–çº¿ç¨‹ä¸­å¼•ç”¨ä¸ä¹‹å…³è”çš„handlerã€‚
        # StringIOå¯¹è±¡ä¼šåœ¨æ²¡æœ‰å¼•ç”¨æ—¶è¢«åƒåœ¾å›æ”¶ã€‚

    return result

def start_processing(accounts, max_workers, gui_queue, stop_event, browser_path=None, save_path=None, desired_keys=0):
    """
    ç¨‹åºåŒ–å…¥å£ç‚¹ï¼Œç”¨äºä»GUIæˆ–å…¶ä»–è„šæœ¬è°ƒç”¨ã€‚
    :param accounts: ä¸€ä¸ªåŒ…å«å…ƒç»„(email, password)çš„åˆ—è¡¨ã€‚
    :param max_workers: å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°ã€‚
    :param gui_queue: ç”¨äºå°†çŠ¶æ€å’Œç»“æœå‘é€å›GUIçš„é˜Ÿåˆ—ã€‚
    :param stop_event: ç”¨äºå…¨å±€åœæ­¢çš„çº¿ç¨‹äº‹ä»¶ã€‚
    :param browser_path: è‡ªå®šä¹‰æµè§ˆå™¨å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„ã€‚
    :param save_path: è‡ªå®šä¹‰å¯†é’¥ä¿å­˜è·¯å¾„ã€‚
    """
    # ä¸»çº¿ç¨‹çš„æ—¥å¿—è®°å½•å™¨ï¼Œåªå‘é€åˆ°GUIé˜Ÿåˆ—
    setup_global_logging(log_queue=gui_queue)
    
    try:
        gcloud_path = check_gcloud_installed()
    except GCloudNotInstalledError as e:
        # è¿™ä¸ªå¼‚å¸¸ä¼šåœ¨ä¸»åŒ…è£…å™¨ä¸­è¢«æ•è·å¹¶æ˜¾ç¤ºç»™ç”¨æˆ·
        raise e

    if not accounts:
        logging.info("æœªæä¾›ä»»ä½•è´¦å·ã€‚")
        return

    logging.info("\n--- æ­£åœ¨å‡†å¤‡æµè§ˆå™¨é©±åŠ¨ (ä»…æ‰§è¡Œä¸€æ¬¡)... ---")
    try:
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æµè§ˆå™¨è·¯å¾„ï¼Œåˆ™ä½¿ç”¨å®ƒ
        if browser_path and os.path.exists(browser_path):
            logging.info(f"ä½¿ç”¨è‡ªå®šä¹‰æµè§ˆå™¨è·¯å¾„: {browser_path}")
            patcher = uc.Patcher(executable_path=browser_path)
        else:
            patcher = uc.Patcher()
        
        patched_driver_path = patcher.executable_path if os.path.exists(patcher.executable_path) else patcher.auto()
        logging.info("âœ… æµè§ˆå™¨é©±åŠ¨å‡†å¤‡å°±ç»ªã€‚")
    except Exception as e:
        logging.critical(f"âŒ åˆå§‹åŒ–æµè§ˆå™¨é©±åŠ¨å¤±è´¥: {e}")
        logging.critical("è¯·ç¡®ä¿å·²å®‰è£…å…¼å®¹çš„Chromeæµè§ˆå™¨ã€‚")
        return

    temp_dirs = []
    try:
        temp_dirs = [tempfile.mkdtemp() for _ in accounts]
        
        logging.info(f"\n--- å°†ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹å¯åŠ¨ {len(accounts)} ä¸ªè´¦å·ä»»åŠ¡... ---")

        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            for i, (email, password) in enumerate(accounts):
                if stop_event.is_set():
                    logging.warning("å¯åŠ¨è¿‡ç¨‹ä¸­æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä¸å†æäº¤æ–°ä»»åŠ¡ã€‚")
                    # å¯¹äºæœªæäº¤çš„ä»»åŠ¡ï¼Œç«‹å³è¿”å›â€œæœªå¤„ç†â€çŠ¶æ€
                    if gui_queue:
                        gui_queue.put({"account": email, "status": STATUS_PENDING, "reason": "è¢«ç”¨æˆ·å¼ºåˆ¶ä¸­æ–­"})
                    continue

                temp_dir = temp_dirs[i]
                logging.info(f"   > æ­£åœ¨ä¸ºè´¦å· '{email}' æäº¤ä»»åŠ¡ï¼Œä½¿ç”¨éš”ç¦»ç¯å¢ƒ: {temp_dir}")
                future = executor.submit(
                    process_account,
                    email,
                    password,
                    gcloud_path,
                    temp_dir,
                    patched_driver_path,
                    stop_event,
                    browser_path,
                    gui_queue,
                    i,
                    desired_keys
                )
                futures[future] = email

            # å½“æ¯ä¸ªä»»åŠ¡å®Œæˆæ—¶ï¼Œç«‹å³é€šè¿‡é˜Ÿåˆ—å‘é€ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                try:
                    account_result = future.result()
                    if gui_queue:
                        gui_queue.put(account_result)
                except Exception as e:
                    # å³ä½¿çº¿ç¨‹å†…éƒ¨å‡ºé”™ï¼Œä¹Ÿè¦å°è¯•è®°å½•
                    logging.error(f"--- ä»»åŠ¡æ‰§è¡ŒæœŸé—´å‘ç”Ÿé¡¶å±‚é”™è¯¯: {e}", exc_info=True)

            # --- æœ€ç»ˆæŠ¥å‘Šå’Œæ–‡ä»¶å†™å…¥ ---
            # è¿™éƒ¨åˆ†é€»è¾‘å°†ç§»è‡³GUIç«¯ï¼Œç”±GUIæ”¶é›†æ‰€æœ‰ç»“æœåç”Ÿæˆ
            # åç«¯åªè´Ÿè´£å¤„ç†å¹¶å‘é€å•ä¸ªç»“æœ
            logging.info("\n" + "="*80)
            logging.info("ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰è´¦å·ä»»åŠ¡å·²æäº¤å¹¶å¤„ç†å®Œæ¯• ğŸ‰ğŸ‰ğŸ‰")
            # ä¸å†åœ¨è¿™é‡Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šæˆ–å†™å…¥æ–‡ä»¶
            # GUIå°†è´Ÿè´£æ”¶é›†æ‰€æœ‰é€šè¿‡é˜Ÿåˆ—å‘é€çš„ç»“æœï¼Œå¹¶å¤„ç†åç»­äº‹å®œ
            logging.info("="*80)

    except Exception:
        logging.critical("\n--- è„šæœ¬ä¸»çº¿ç¨‹å› æ„å¤–é”™è¯¯è€Œä¸­æ–­ ---", exc_info=True)
    finally:
        logging.info("\n--- æ­£åœ¨æ¸…ç†æ‰€æœ‰ä¸´æ—¶éš”ç¦»ç¯å¢ƒ... ---")
        for temp_dir in temp_dirs:
            try:
                shutil.rmtree(temp_dir, ignore_errors=True)
                logging.info(f"   > å·²æ¸…ç†: {temp_dir}")
            except Exception:
                 logging.warning(f"   > æ¸…ç†å¤±è´¥: {temp_dir}", exc_info=True)


def main():
    """ä¸ºå‘½ä»¤è¡Œä½¿ç”¨ä¿ç•™çš„åŸå§‹mainå‡½æ•°ã€‚"""
    setup_global_logging()
    
    accounts_from_args = []
    if len(sys.argv) > 1:
        if len(sys.argv[1:]) % 2 != 0:
            logging.critical("âŒ é”™è¯¯: å‘½ä»¤è¡Œå‚æ•°å¿…é¡»æ˜¯è´¦å·å’Œå¯†ç æˆå¯¹å‡ºç°ã€‚")
            sys.exit(1)
        for i in range(0, len(sys.argv[1:]), 2):
            accounts_from_args.append((sys.argv[i+1], sys.argv[i+2]))
    
    if accounts_from_args:
        accounts = accounts_from_args
    else:
        accounts = []
        logging.info("--- è¯·é€ä¸ªè¾“å…¥æ‚¨çš„Googleè´¦å·å’Œå¯†ç  ---")
        logging.info("   (è¾“å…¥ä¸€ä¸ªç©ºçš„è´¦å·åæ¥ç»“æŸ)")
        while True:
            try:
                email = input("â–¶ï¸  è´¦å·é‚®ç®±: ").strip()
                if not email:
                    break
                password = getpass.getpass("â–¶ï¸  å¯†ç  (è¾“å…¥æ—¶ä¸å¯è§): ")
                if not password:
                    logging.warning("âŒ å¯†ç ä¸èƒ½ä¸ºç©ºã€‚è¯·é‡æ–°è¾“å…¥è¯¥è´¦å·ã€‚")
                    continue
                accounts.append((email, password))
            except KeyboardInterrupt:
                logging.info("\næ“ä½œå·²å–æ¶ˆã€‚")
                sys.exit(0)

    if not accounts:
        logging.info("æœªè¾“å…¥ä»»ä½•è´¦å·ã€‚")
        sys.exit(0)
    
    max_workers = 4
    if not accounts_from_args:
        while True:
            try:
                max_workers_str = input(f"â–¶ï¸  è¯·è¾“å…¥æœ€å¤§å¹¶å‘çº¿ç¨‹æ•° (æ¨è 1-{os.cpu_count() or 4}, é»˜è®¤ä¸º 4): ")
                if not max_workers_str:
                    break
                max_workers = int(max_workers_str)
                if max_workers > 0:
                    break
                else:
                    logging.warning("âŒ è¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚")
            except ValueError:
                logging.warning("âŒ æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ•°å­—ã€‚")

    # æ³¨æ„ï¼šåœ¨å‘½ä»¤è¡Œæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨log_queue
    start_processing(accounts, max_workers, None)

    if sys.platform == "win32":
        logging.info("\næŒ‰ä»»æ„é”®é€€å‡º...")
        os.system("pause")


if __name__ == "__main__":
    main()